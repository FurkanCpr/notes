{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4-Training Model.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNMmg6cKl8KsnH1MY2FSoTZ"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"PJZn90MB9Zep","colab_type":"code","colab":{}},"source":["import torch\n","# Torchvision, içinde bulunduğu datasetleri bize görsel olarak sunan bir kütüphanedir.\n","import torchvision\n","from torchvision import transforms,datasets"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MGN4bpd09gvm","colab_type":"code","colab":{}},"source":["# Sentdex diyorki, neden transforms ettiğimizi bilmiyorum, tek bildiğim datanın Tensöre nazaran daha farklı gelmesinden ötürü Tensöre çevirmemiz.\n","train = datasets.MNIST(\"\", train=True, download=True, transform=transforms.Compose([transforms.ToTensor()])) \n","\n","test = datasets.MNIST(\"\", train=False, download=True, transform=transforms.Compose([transforms.ToTensor()]))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ICxr1zy29kh6","colab_type":"code","colab":{}},"source":["trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n","\n","testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sGfHVJSj9lFv","colab_type":"code","colab":{}},"source":["import torch.nn as nn\n","import torch.nn.functional as F"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4cOuRQXP928M","colab_type":"code","outputId":"f6af7b28-f305-497b-c26d-7814448fb6b7","executionInfo":{"status":"ok","timestamp":1590359298500,"user_tz":-180,"elapsed":447,"user":{"displayName":"Furkan Çapar","photoUrl":"","userId":"00596429511863753860"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["class Net(nn.Module):\n","  # nn.Module olan Inherited(miras alınan class demektir böylece ismi yazılan classın özellikleri alınmış olur.)Classının init özelliklerini alır.\n","  def __init__(self):\n","    # Eğer super().__init__() i silersek, cannot assign module before Module.__init__() call errorunu verir.\n","    super().__init__()\n","    # Buradaki sayılar neuron sayısını belirtir. nn.Linear(input, output)\n","    # fc is fully connected'a ithafendir.\n","    self.fc1 = nn.Linear(28*28, 64)\n","    self.fc2 = nn.Linear(64, 64)\n","    self.fc3 = nn.Linear(64, 64)\n","    self.fc4 = nn.Linear(64, 10)\n","  def forward(self, x):\n","    x = F.relu(self.fc1(x)) #F.relu aktivasyon fonksiyonumuzdur.   \n","    x = F.relu(self.fc2(x))\n","\n","    #Aktivasyon fonksiyonlarını, layerlarını istediğin gibi tasarlama şansın var.\n","    # örneğin if else,try except gibi istediğin statemantları ekleyip lojik yazabilirsin.\n","    x = F.relu(self.fc3(x))\n","    x = self.fc4(x)\n","    return F.log_softmax(x, dim=1)\n","\n","net = Net()\n","print(net)\n","\n"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Net(\n","  (fc1): Linear(in_features=784, out_features=64, bias=True)\n","  (fc2): Linear(in_features=64, out_features=64, bias=True)\n","  (fc3): Linear(in_features=64, out_features=64, bias=True)\n","  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"39hDnCFbFBAW","colab_type":"code","colab":{}},"source":["X = torch.rand((28,28))\n","# -1'in anlamı, buradaki inputun shape'inin bilinmemesidir. 1 ile devam edebiliriz ikiside aynı cevabı verir.\n","X = X.view(1,28*28)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xl4zv5f9eWjs","colab_type":"code","colab":{}},"source":["output = net(X)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xB37BtUse7ii","colab_type":"code","outputId":"4c1f3b5f-59e3-4305-ef9d-79936353cc9b","executionInfo":{"status":"ok","timestamp":1590359301783,"user_tz":-180,"elapsed":489,"user":{"displayName":"Furkan Çapar","photoUrl":"","userId":"00596429511863753860"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["output\n","#grad_fn, gradient descent'deki gibi "],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-2.2015, -2.3299, -2.2723, -2.3608, -2.1821, -2.3560, -2.4251, -2.1780,\n","         -2.3625, -2.3956]], grad_fn=<LogSoftmaxBackward>)"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"ECzrba5mf26h","colab_type":"code","outputId":"7fcb14c8-5b99-4b6e-8908-dd8dc23e35b3","executionInfo":{"status":"ok","timestamp":1590359349318,"user_tz":-180,"elapsed":46957,"user":{"displayName":"Furkan Çapar","photoUrl":"","userId":"00596429511863753860"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["#Loss = Modelin ne kadar yanlış, modelin tahmininin doğruluğunu ölçmemiz için kullandığımız bir konsepttir.\n","#Optimizer = loss, weights gibi parametreleri ayarlar dengelemeye çalışır.\n","import torch.optim as optim\n","\n","optimizer = optim.Adam(net.parameters(), lr=0.001)\n","# Learning rate'i iyi ayarlaman lazım. Eğer lr olması gerekenden büyük olursa asıl olan değere hiçbir zaman yaklaşamayacak;\n","# Eğer lr olması gerekenden küçük olursa taradığı alandan dışarı çıkamayacak ve en optimum değeri bulamayacak.\n","# Datalamızı belirli sayıda yineleyerek(iterate) datayı taramak istiyorsan epoch adında bir kelimeden bahsederiz.\n","\n","EPOCHS = 3\n","\n","for epoch in range(EPOCHS):\n","  for data in trainset:\n","    # data is a batch of featuresets and labels\n","    X, y = data\n","    \"\"\"\n","    #Image arrayları\n","    print(X[0])\n","    #tensor(6) = 6 sayısının bilgisini verir.\n","    print(y[0])\n","    #import matplotlib.pyplot as plt\n","    #plt.imshow(data[0][0].view(28,28))\n","    \"\"\"\n","    net.zero_grad()\n","    output = net(X.view(-1, 28*28))\n","    loss = F.nll_loss(output, y)\n","    loss.backward()\n","    # Ağırlıkları ayarlar.\n","    optimizer.step()  \n","  # Parantez içindeki sayılar loss değerlerimizdir.\n","  print(loss)\n"],"execution_count":20,"outputs":[{"output_type":"stream","text":["tensor(0.5892, grad_fn=<NllLossBackward>)\n","tensor(0.0542, grad_fn=<NllLossBackward>)\n","tensor(0.2741, grad_fn=<NllLossBackward>)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tES7Hv8JAjtV","colab_type":"code","outputId":"d91fa97c-0bc8-40be-d744-ceaf0ab90608","executionInfo":{"status":"error","timestamp":1590359381545,"user_tz":-180,"elapsed":668,"user":{"displayName":"Furkan Çapar","photoUrl":"","userId":"00596429511863753860"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["# Lets see how correct were;\n","correct = 0\n","total = 0 \n","# In this case, when we act when we're trying to validate(doğrulamak) our data we actually dont want gradients to be calculated\n","# This is supposed to be out of sample data, this is testing data. We just want to see how right or wrong is the model we dont actually want to optimize based on this data\n","# We dont wanna count gradients here we just to know how good is the network at this point\n","with torch.no_grad():\n","  # model.train() and model.eval() activates and deactivates Dropout and BatchNorm, so it is quite important. \"with torch.no_grad()\" only deactivates gradient calculations,\n","  # but doesn't turn off Dropout and BatchNorm. Your model accuracy will therefore be lower if you don't use model.eval() when evaluating the model.\n","  for data in trainset():\n","    X, y = data\n","    output = net(X.view(-1, 784))\n","    for idx, i in enumerate(output):\n","      if torch.argmax(i) == y[idx]:\n","        correct += 1\n","      total += 1\n","print(\"Accuracy:\", round(correct/total, 3))"],"execution_count":23,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-2dbf87a659e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;31m# model.train() and model.eval() activates and deactivates Dropout and BatchNorm, so it is quite important. \"with torch.no_grad()\" only deactivates gradient calculations,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;31m# but doesn't turn off Dropout and BatchNorm. Your model accuracy will therefore be lower if you don't use model.eval() when evaluating the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m784\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object is not callable"]}]},{"cell_type":"code","metadata":{"id":"LxvQqkSWapUS","colab_type":"code","colab":{}},"source":[" "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-BTa1eZGwK-c","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}